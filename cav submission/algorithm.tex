\section{The Algorithm}
\label{sec:algorithm}
\subsection{Synthesis Graph Construction}
\label{sec:algorithm:graph}

Our algorithm operates by searching through a specially-crafted data
structure called the {\emph{synthesis graph}}. Each node of the synthesis graph
corresponds to either a value-producing language entity, such as a
function, variable, constant, or literal, or to a type in the
language. We therefore devide nodes into two sets $V_t$ (type nodes) and $V_f$ (function nodes). 
Since variables, constants, and literals can be considered
functions taking the empty set to their value, we call all nodes of
the former type ``function nodes''. From each function node, there is 
an out-edge to the type it produces, and for each distinct type the
function takes as an argument, we draw an incoming edge into the
function node to the type node. Importantly, this means that a
function on three input parameters of the same type will have
in-degree exactly one.

Each vertex is labeled by the full function signature so that
well-typed expressions can be synthesized. The edges in the graph are
weighted by their cost of inclusion -- a subjective measure -- that
guides the search towards desirable traits, such as smaller
expressions or lower memory usage.

\iffalse
The algorithm uses two procedures, along with some supporting
subroutines, to accomplish expression repairs by referring to this
graph. The repair algorithm itself degenerates into simple expression
synthesis when presented with an empty broken expression, and as such
subsumes the functionality described in
\cite{GveroETAL13CompleteCompletionTypesWeights}. Furthermore, the
algorithm can be seen as a generalization of the Prospector algorithm
described in \cite{MandelinetALL2005Jungloid}, since their
construction can be embedded within ours if only unary operations and
types are added to the graph.
\fi

\subsection{Synthesis Procedure}
\label{sec:algorithm:synthesis}
We will now describe the synthesis portion of our algorithm, which is
presented as pseudocode in algorithm \ref{proc:synthesize}. Note that
to distinguish type nodes $V_t$ from function nodes $V_f$, we will
write the synthesis graph $G=(V_t \cup V_f, E)$.

\SetKwData{Snips}{snips}
\begin{algorithm}
\SetKwData{Exprs}{exprs}
\SetKwFunction{Dist}{Dist}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{$G=(V_t\cup V_f,E)$, the synthesis graph; $\tau \in V_t$, the type to synthesize; $C_{max}$, the maximum allowable cost; $N$, the number of snippets to synthesize}
\Output{\Exprs, the list of expressions}
\BlankLine
$G'=(V_t'\cup V_f', E') \longleftarrow$ subgraph of $G$ reachable within $C_{max}$ from $\tau$ \;
Sort $V_t'$ in descending distance away from $\tau$ \;
\Snips $\longleftarrow$ Hash table mapping types to snippets \;
\ForEach{$\sigma\in V_t'$}{
  \Snips[$\sigma$] $\longleftarrow$ \ref{proc:getExpression}($G'$, \Snips, $\sigma$, $C_{max} - $ \Dist{$\tau$, $\sigma$}, $N$) \;
}
\Exprs $\longleftarrow$ \Snips[$\tau$] \;
\caption{Synthesis Algorithm}\label{proc:synthesize}
\end{algorithm}

The subgraph is derived by using Dijkstra's algorithm, which can also
accomplish the vertex sort by distance. We go in reverse order so as
to cache at the latest possible opportunity. At any stage of the loop,
we know that $\sigma$ is as close as possible to $\tau$ and so if we
create an expression for $\tau$ that involves $\sigma$ along the way,
we know that the rest of the expression may cost at most $C_{max} - $
\Dist{$\sigma$}. The procedure \ref{proc:getExpression} uses \Snips to
avoid performing expensive recomputations.

Now, we describe the \ref{proc:getExpression} procedure, whose task is
to find the $N$ best snippets for type $\sigma$ in $G'$ within a
prescribed cost bound $C_{now}$.
\begin{procedure}
\SetKwFunction{Cost}{Cost}\SetKwFunction{Keys}{Keys}
\SetKwData{Results}{results}
\lIf{$\sigma$ $\in$ \Keys{\Snips}}{\Return{\Snips$[\sigma]$}}
\Results $\leftarrow$ $\emptyset$ \;
\ForEach{$g \in V_f'$ of the form $g : (\tau_1 \times \cdots \times \tau_k) \to \sigma$}{
	\lIf{\Cost{$g$} $> C_{now}$}{\KwContinue}
	For all $i$, let $s_i \leftarrow$ \ref{proc:getExpression}($G'$, \Snips, $\tau_i, C_{now} - $ \Cost{$g$}, $N$) \;
	\ForEach{args $\in$ $s_1 \times \cdots \times s_k$}{
		\If{\Cost{$g$(args)} $\leq C_{now}$}{
			Add $g$(args) to \Results \;
		}
		\While{$|$ \Results $| > N$}{
			Remove the most costly entry from \Results \;
		}
	}
}
\Return{\Results}
\caption{GetExpressions({$G'=(V_t' \cup V_f', E')$}, snips, $\sigma, C_{now}, N$)}\label{proc:getExpression}
\end{procedure}
The procedure operates recursively, and it checks to see whether the
computation has been completed before by referring to the \Snips
table. To carry out the computation for $\sigma$ it looks at its
neighbors in the graph that correspond to its out-edges, those
indicating a ``constructed-from'' relationship. As long as that
function would not immediately break the cost constraint, it attempts
to satisfy all of its argument types recursively. This only needs to
be done once for each type. Then, for every possible set of arguments
to the function, it adds the allowable expressions to the results, and
pushes out the worst few results if the size of the set would exceed
$N$.

\subsection{Repair Algorithm}
\label{sec:algorithm:repair}
We are now ready to describe the repair algorithm. The key step in our
approach is biasing the previously-described synthesis procedures
towards those subexpressions of the broken expression that are
correctly-typed. The intuition for this is that if a user tries to
create an object from some specific components, the search should be
optimized to favor those components. To do this, we adjust the \Cost
function used by \ref{proc:getExpression}. \Cost will now scale down
its results by a factor of $2^n$, where $n$ is the number of
expressions ``reinforced'' by the repair procedure that appear in the
snippet. As a practical matter, we say we have ``reinforced'' an
expression when we add it to a list of reinforced expressions.

This scheme has a few distinct advantages: first, it will very
strongly prefer those expressions that occurred as part of the given
incorrect expression; second, in cases where more than one of the same
type is required, it will favor using multiple, distinct
subexpressions among those reinforced (ie. it will prefer to use both
$a$ and $b$ over just one if both were specified); and finally, if no
expressions are specified, then \Cost actually remains unchanged.

With this modification in place, the repair algorithm proceeds from
the bottom up. For each broken sub-expression in the input, we first
reinforce each of its well-typed subexpressions and then initiate a
synthesis for the desired type of the current subexpression. If any of
its children are ill-typed, we recurse and repair them first.
\begin{algorithm}
\SetKwData{Repairs}{repairs}\SetKwData{Expr}{expr}
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{$G=(V_t\cup V_f,E)$, the synthesis graph; \Expr, the broken expression; $C_{max}$, the maximum allowable cost; $N$, the number of repairs to synthesize}
\Output{\Repairs}
\BlankLine
\lIf{\Expr is well-typed}{\Return{expr}}
Since \Expr results in a value, we write it as \Expr$(x_1, \ldots, x_k)$ where the $x_i$ are the subexpressions of type $\tau_i$ making up \Expr.
\ForEach{$x\in\{x_1,\ldots,x_k\}$}{
  $x' \longleftarrow$ Repair ($G, x, C_{max}, N$) \;
  Reinforce $x'$ for this subtree and above \;
}
\Repairs $\longleftarrow$ Synthesize ($G, \tau, C_{max}, N$)
\caption{Repair Algorithm}\label{proc:repair}
\end{algorithm}
Notice that this means the repaired subexpressions will also be
reinforced. This behavior is desirable because it favors reusing the
subexpressions generated once the repair synthesizes a higher
level. Additionally, the recursion guarantees that reinforcing a
subexpression will not interfere with a synthesis that occurs at the
same level as that subexpression.

Although this algorithm, as described, returns up to $N$ possible
repairs, in our preliminary implementation, we found that the first
result was always the most correct, so even setting $N=1$ might be
acceptable in a practical setting.

\iffalse

\subsection{Completeness Guarantees}

Because the algorithm is limited only by user defined parameters, the
search can be tuned to consider every node in the graph. Since the
breadth and depth restrictions can be elided by increasing the cost
and quantity limits, the full space of possible expressions is
reachable. Note, however, that without a cost limit, the algorithm
will not terminate, since many copy-constructors or other identity
maps often times exist in the environment (e.g. one could synthesize
$f(f(f(f(\ldots f(a)\ldots ))))$ ad infinitum). Even with a cost
limit, it was shown in
\cite{GveroETAL13CompleteCompletionTypesWeights} that the expression
synthesis problem corresponds to the type-inhabitation problem, which
is known to be PSPACE-complete \cite{Urzyczyn97}. Fortunately, finding
a neighborhood for a type runs in polynomial time (same as Dijkstra's
algorithm), and although we have no proven time bounds on the search,
it has been extremely fast in practice. Thus, we know that since this
problem is PSPACE-complete, there always exists a cost limit larger
than the entire graph, but finite such that if an expression exists,
it can be found by the algorithm in finite time.

\fi
